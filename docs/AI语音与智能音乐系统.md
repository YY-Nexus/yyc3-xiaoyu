# AI语音与智能音乐系统技术文档

---

## 系统概述

YYC3 AI小语智能成长守护系统的语音交互模块采用Web Speech API实现浏览器原生语音能力，结合自研的多模态情感融合算法，为儿童提供自然、温暖的语音交互体验。

**核心设计理念**:
- 零依赖：无需额外语音服务API密钥，降低部署成本
- 优雅降级：在受限环境自动降级，确保功能可用
- 儿童友好：针对儿童语音特点优化识别参数
- 情感感知：语音+文本双模态情感融合分析

---

## 1. 语音交互系统架构

### 1.1 核心类: VoiceInteractionSystem

**文件位置**: `lib/voice/voice-system.ts`

**架构设计**:

\`\`\`
┌─────────────────────────────────────────────────────────────┐
│                  VoiceInteractionSystem                      │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │
│  │ 语音识别    │  │ 语音合成    │  │ 音频分析器          │  │
│  │ (STT)       │  │ (TTS)       │  │ (AudioAnalyser)     │  │
│  │             │  │             │  │                     │  │
│  │ Web Speech  │  │ Speech      │  │ Web Audio API       │  │
│  │ Recognition │  │ Synthesis   │  │ FFT分析             │  │
│  └─────────────┘  └─────────────┘  └─────────────────────┘  │
│                          │                                   │
│  ┌───────────────────────┴───────────────────────────────┐  │
│  │              语音情感分析引擎                           │  │
│  │  - 音高(Pitch)检测                                     │  │
│  │  - 能量(Energy)计算                                    │  │
│  │  - 变化率(Variation)分析                               │  │
│  │  - 情感分类(7类情绪)                                   │  │
│  └───────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
\`\`\`

### 1.2 核心功能实现

#### 语音识别 (Speech-to-Text)

\`\`\`typescript
// 实际项目实现 - lib/voice/voice-system.ts

export class VoiceInteractionSystem {
  private recognition: any = null
  private isListening = false
  
  constructor() {
    if (typeof window !== "undefined") {
      this.initialize()
    }
  }

  private initialize() {
    const SpeechRecognition = 
      (window as any).SpeechRecognition || 
      (window as any).webkitSpeechRecognition

    if (SpeechRecognition) {
      this.recognition = new SpeechRecognition()
      this.recognition.lang = "zh-CN"        // 中文识别
      this.recognition.continuous = false    // 非持续模式避免网络错误
      this.recognition.interimResults = true // 实时中间结果
      this.recognition.maxAlternatives = 1
    }
  }

  startListening(
    onResult: (result: SpeechRecognitionResult) => void, 
    onError?: (error: Error) => void
  ): void {
    if (!this.recognition || this.isListening) return
    
    // 环境检测 - v0预览环境自动跳过
    if (this.isRestrictedEnvironment()) {
      console.log("[v0] 语音识别在当前环境不可用")
      return
    }

    this.recognition.onresult = (event: any) => {
      const result = event.results[event.results.length - 1]
      onResult({
        transcript: result[0].transcript.trim(),
        confidence: result[0].confidence,
        isFinal: result.isFinal,
      })
    }

    this.recognition.start()
  }
}
\`\`\`

**配置参数**:

| 参数 | 值 | 说明 |
|------|-----|------|
| lang | zh-CN | 中文普通话识别 |
| continuous | false | 单次识别模式，避免网络超时 |
| interimResults | true | 启用实时中间结果反馈 |
| maxAlternatives | 1 | 返回最佳识别结果 |

#### 语音合成 (Text-to-Speech)

\`\`\`typescript
// 实际项目实现

async speak(
  text: string,
  options?: {
    rate?: number    // 语速 0.1-10
    pitch?: number   // 音调 0-2
    volume?: number  // 音量 0-1
  }
): Promise<void> {
  if (!this.synthesis) return

  return new Promise((resolve) => {
    this.synthesis!.cancel()

    const utterance = new SpeechSynthesisUtterance(text)
    utterance.lang = "zh-CN"
    utterance.rate = options?.rate || 1.0
    utterance.pitch = options?.pitch || 1.0
    utterance.volume = options?.volume || 1.0

    // 自动选择中文语音
    const voices = this.synthesis!.getVoices()
    const chineseVoice = voices.find((v) => v.lang.includes("zh"))
    if (chineseVoice) {
      utterance.voice = chineseVoice
    }

    utterance.onend = () => resolve()
    utterance.onerror = () => resolve() // 失败时也resolve避免阻塞
    
    this.synthesis!.speak(utterance)
  })
}
\`\`\`

#### 情感化语音合成

\`\`\`typescript
// AI角色语音风格配置

async speakWithRole(
  text: string,
  roleStyle: "cheerful" | "calm" | "gentle" | "professional" | "warm"
): Promise<void> {
  const styleSettings = {
    cheerful:     { rate: 1.1,  pitch: 1.15, volume: 1.0  },  // 记录者
    calm:         { rate: 0.95, pitch: 1.0,  volume: 0.9  },  // 守护者
    gentle:       { rate: 0.9,  pitch: 1.05, volume: 0.85 },  // 聆听者
    professional: { rate: 1.0,  pitch: 0.95, volume: 1.0  },  // 建议者
    warm:         { rate: 0.95, pitch: 1.1,  volume: 0.95 },  // 国粹导师
  }

  await this.speak(text, styleSettings[roleStyle])
}
\`\`\`

### 1.3 语音唤醒功能

\`\`\`typescript
// 唤醒词检测实现

startWakeWordListening(onWakeWord: () => void): void {
  // 环境安全检测
  if (typeof window === "undefined") return
  
  try {
    if (window.self !== window.top) return // iframe环境跳过
  } catch {
    return
  }

  this.wakeWordCallback = onWakeWord
  this.wakeWordEnabled = true

  this.recognition.onresult = (event: any) => {
    const transcript = event.results[0][0].transcript.toLowerCase()

    // 支持的唤醒词
    const wakeWords = ["小语", "小雨", "hey xiaoyu", "你好小语"]
    
    if (wakeWords.some(word => transcript.includes(word))) {
      this.wakeWordDetected = true
      this.wakeWordCallback?.()
      this.playWakeSound() // 播放唤醒确认音效
    }
  }

  this.startSingleRecognition()
}

// 唤醒确认音效
private playWakeSound(): void {
  const audioContext = new AudioContext()
  const oscillator = audioContext.createOscillator()
  const gainNode = audioContext.createGain()

  oscillator.connect(gainNode)
  gainNode.connect(audioContext.destination)

  // 双音提示 800Hz -> 1000Hz
  oscillator.frequency.setValueAtTime(800, audioContext.currentTime)
  oscillator.frequency.setValueAtTime(1000, audioContext.currentTime + 0.1)

  gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
  gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.2)

  oscillator.start(audioContext.currentTime)
  oscillator.stop(audioContext.currentTime + 0.2)
}
\`\`\`

---

## 2. 语音情感分析引擎

### 2.1 音频特征提取

**文件位置**: `lib/voice/voice-system.ts`

\`\`\`typescript
// Web Audio API音频分析

async initAudioAnalyser(): Promise<boolean> {
  this.audioContext = new AudioContext()
  this.analyser = this.audioContext.createAnalyser()
  this.analyser.fftSize = 2048
  this.analyser.smoothingTimeConstant = 0.8

  this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })
  const source = this.audioContext.createMediaStreamSource(this.mediaStream)
  source.connect(this.analyser)

  return true
}

getAudioFeatures(): { pitch: number; energy: number; variation: number } | null {
  if (!this.analyser) return null

  const bufferLength = this.analyser.frequencyBinCount
  const dataArray = new Uint8Array(bufferLength)
  const timeData = new Uint8Array(bufferLength)

  this.analyser.getByteFrequencyData(dataArray)
  this.analyser.getByteTimeDomainData(timeData)

  // 1. 能量计算 (RMS)
  let sum = 0
  for (let i = 0; i < timeData.length; i++) {
    const val = (timeData[i] - 128) / 128
    sum += val * val
  }
  const energy = Math.sqrt(sum / timeData.length) * 100

  // 2. 音高检测 (基频)
  let maxIndex = 0, maxValue = 0
  for (let i = 0; i < dataArray.length / 2; i++) {
    if (dataArray[i] > maxValue) {
      maxValue = dataArray[i]
      maxIndex = i
    }
  }
  const sampleRate = this.audioContext?.sampleRate || 44100
  const pitch = (maxIndex * sampleRate) / this.analyser.fftSize

  // 3. 变化率计算
  let variation = 0
  for (let i = 1; i < dataArray.length; i++) {
    variation += Math.abs(dataArray[i] - dataArray[i - 1])
  }
  variation = variation / dataArray.length

  return { pitch, energy, variation }
}
\`\`\`

### 2.2 语音情感分类算法

\`\`\`typescript
// 7类情感分类

private classifyVoiceEmotion(
  pitch: number,
  energy: number,
  variation: number,
  tempo: number
): { emotion: string; confidence: number; suggestion: string } {
  
  let emotion = "neutral"
  let confidence = 0.6
  let suggestion = ""

  // 分类规则 (基于音频特征阈值)
  if (pitch > 250 && energy > 30 && variation > 15) {
    emotion = "excited"
    confidence = 0.85
    suggestion = "检测到兴奋情绪，孩子可能有开心的事情想分享"
  } 
  else if (pitch > 200 && energy > 20 && variation > 10) {
    emotion = "happy"
    confidence = 0.8
    suggestion = "孩子心情不错，这是交流的好时机"
  } 
  else if (pitch < 150 && energy < 15 && variation < 8) {
    emotion = "sad"
    confidence = 0.75
    suggestion = "检测到低落情绪，建议给予更多关注和倾听"
  } 
  else if (energy > 35 && tempo > 180) {
    emotion = "angry"
    confidence = 0.7
    suggestion = "情绪有些激动，建议先让孩子冷静下来再沟通"
  } 
  else if (energy > 25 && variation > 20 && tempo > 150) {
    emotion = "anxious"
    confidence = 0.7
    suggestion = "可能有些焦虑，尝试用平静的语气安抚"
  } 
  else if (energy < 20 && variation < 10 && tempo < 100) {
    emotion = "calm"
    confidence = 0.75
    suggestion = "状态平静，适合进行学习或认真对话"
  }

  return { emotion, confidence, suggestion }
}
\`\`\`

**情感分类特征阈值表**:

| 情感 | 音高(Hz) | 能量 | 变化率 | 语速 | 置信度 |
|------|---------|------|--------|------|--------|
| excited | >250 | >30 | >15 | - | 0.85 |
| happy | >200 | >20 | >10 | - | 0.80 |
| sad | <150 | <15 | <8 | - | 0.75 |
| angry | - | >35 | - | >180 | 0.70 |
| anxious | - | >25 | >20 | >150 | 0.70 |
| calm | - | <20 | <10 | <100 | 0.75 |
| neutral | 其他 | 其他 | 其他 | 其他 | 0.60 |

---

## 3. 多模态情感融合系统

### 3.1 融合算法

**文件位置**: `lib/multimodal-fusion.ts`

\`\`\`typescript
// 多模态情感融合核心算法

export class MultimodalEmotionFusion {
  // 融合权重配置
  private FUSION_WEIGHTS = {
    text: 0.4,   // 文本情感权重
    voice: 0.6,  // 语音情感权重（更准确）
  }

  fuseEmotions(
    textEmotion?: TextEmotionData, 
    voiceEmotion?: VoiceEmotionData
  ): FusedEmotionResult {
    // 单模态降级
    if (!textEmotion && !voiceEmotion) return this.createNeutralResult()
    if (!voiceEmotion) return this.createResultFromText(textEmotion!)
    if (!textEmotion) return this.createResultFromVoice(voiceEmotion)

    // 双模态融合
    return this.performFusion(textEmotion, voiceEmotion)
  }

  private performFusion(text: TextEmotionData, voice: VoiceEmotionData) {
    // 基于Russell环状模型的Valence-Arousal融合
    const textMapping = EMOTION_MAPPING[text.type]
    const voiceMapping = EMOTION_MAPPING[voice.type]

    // 加权融合
    const fusedValence =
      textMapping.valence * this.FUSION_WEIGHTS.text * text.confidence +
      voiceMapping.valence * this.FUSION_WEIGHTS.voice * voice.confidence

    const fusedArousal =
      textMapping.arousal * this.FUSION_WEIGHTS.text * text.confidence +
      voiceMapping.arousal * this.FUSION_WEIGHTS.voice * voice.confidence

    // 归一化
    const totalWeight = 
      this.FUSION_WEIGHTS.text * text.confidence + 
      this.FUSION_WEIGHTS.voice * voice.confidence

    const normalizedValence = fusedValence / totalWeight
    const normalizedArousal = fusedArousal / totalWeight

    // 反推情感类型
    const dominantEmotion = this.classifyFromDimensions(
      normalizedValence, 
      normalizedArousal
    )

    return {
      dominantEmotion,
      confidence: this.calculateFusedConfidence(text, voice),
      valence: normalizedValence,
      arousal: normalizedArousal,
      ...this.generateRecommendations(dominantEmotion)
    }
  }
}
\`\`\`

### 3.2 Russell环状情感模型

\`\`\`typescript
// 情感类型 -> Valence/Arousal 映射

const EMOTION_MAPPING: Record<string, { valence: number; arousal: number }> = {
  happy:      { valence:  0.8, arousal: 0.6 },  // 正面+中高激活
  excited:    { valence:  0.9, arousal: 0.9 },  // 正面+高激活
  calm:       { valence:  0.5, arousal: 0.2 },  // 正面+低激活
  neutral:    { valence:  0.0, arousal: 0.3 },  // 中性+低激活
  sad:        { valence: -0.7, arousal: 0.3 },  // 负面+低激活
  angry:      { valence: -0.8, arousal: 0.9 },  // 负面+高激活
  anxious:    { valence: -0.5, arousal: 0.8 },  // 负面+中高激活
  tired:      { valence: -0.3, arousal: 0.1 },  // 轻负面+很低激活
  curious:    { valence:  0.6, arousal: 0.5 },  // 正面+中激活
  frustrated: { valence: -0.6, arousal: 0.7 },  // 负面+中高激活
}
\`\`\`

**Russell环状模型可视化**:

\`\`\`
                    高激活 (Arousal=1.0)
                          │
              excited     │     angry
                   ●      │      ●
                          │
   happy ●                │                ● anxious
                          │
─────────────────────────┼─────────────────────────
   负面 (Valence=-1)      │        正面 (Valence=1)
                          │
   sad ●                  │                ● calm
                          │
              tired ●     │     ● neutral
                          │
                    低激活 (Arousal=0.0)
\`\`\`

---

## 4. 文本情感分析API

### 4.1 API端点

**文件位置**: `app/api/ai/emotion/route.ts`

**请求格式**:

\`\`\`typescript
POST /api/ai/emotion

Request Body:
{
  "text": "今天我好开心，作业全做完了！",
  "includeAdvice": true
}

Response:
{
  "emotion": "happy",
  "confidence": 0.75,
  "valence": 0.8,
  "arousal": 0.6,
  "keywords": ["开心", "好"],
  "advice": "保持这种积极的心态，继续努力！可以和家人分享你的快乐哦~"
}
\`\`\`

### 4.2 情感词典

\`\`\`typescript
const emotionKeywords = {
  happy: {
    words: ["开心", "高兴", "快乐", "哈哈", "棒", "好", "喜欢", "爱", "赞", "耶", "太好了"],
    valence: 0.8,
    arousal: 0.6,
  },
  sad: {
    words: ["难过", "伤心", "哭", "失望", "不开心", "郁闷", "沮丧", "悲伤"],
    valence: -0.7,
    arousal: 0.4,
  },
  angry: {
    words: ["生气", "愤怒", "讨厌", "烦", "恼火", "火大", "气死了"],
    valence: -0.8,
    arousal: 0.9,
  },
  excited: {
    words: ["兴奋", "激动", "太棒了", "超级", "amazing", "精彩"],
    valence: 0.9,
    arousal: 0.95,
  },
  calm: {
    words: ["平静", "放松", "舒服", "安静", "淡定", "还好"],
    valence: 0.3,
    arousal: 0.2,
  },
  anxious: {
    words: ["紧张", "担心", "焦虑", "害怕", "怕", "不安", "忧虑"],
    valence: -0.5,
    arousal: 0.8,
  },
}
\`\`\`

---

## 5. 前端组件

### 5.1 语音输入按钮

**文件位置**: `components/ai-xiaoyu/VoiceInputButton.tsx`

**功能特性**:
- 按住说话，松开发送
- 实时声波动画反馈
- 中间识别结果实时显示
- 音量指示器

\`\`\`tsx
<VoiceInputButton 
  onTranscript={(text) => handleVoiceInput(text)} 
  disabled={false}
/>
\`\`\`

### 5.2 声波可视化动画

**文件位置**: `components/growth/VoiceWaveAnimation.tsx`

**功能特性**:
- Canvas绘制声波柱状图
- 基于audioLevel实时变化
- 渐变颜色效果
- 脉冲扩散动画

\`\`\`tsx
<VoiceWaveAnimation 
  isActive={isRecording}
  audioLevel={currentAudioLevel}
  color="#3b82f6"
  barCount={5}
/>
\`\`\`

### 5.3 情感指示器

**文件位置**: `components/ai-xiaoyu/EmotionIndicator.tsx`

**功能特性**:
- 实时情感状态显示
- 情感对应Emoji图标
- 置信度百分比
- 个性化建议展示

---

## 6. 智能音乐系统(规划中)

### 6.1 功能规划

**情绪感知音乐推荐**:
- 根据检测到的情绪自动推荐音乐
- happy -> 欢快儿歌
- calm -> 轻音乐/摇篮曲
- sad -> 温暖治愈音乐
- excited -> 节奏感强的音乐

**场景化音乐**:
- 睡前故事背景音乐
- 学习专注音乐
- 运动活力音乐
- 放松冥想音乐

### 6.2 技术方案

\`\`\`typescript
// 音乐推荐接口(规划)
interface MusicRecommendation {
  emotion: string
  activity?: string
  timeOfDay?: string
}

// 推荐结果
interface MusicTrack {
  id: string
  title: string
  artist: string
  duration: number
  url: string
  tags: string[]
  suitableEmotions: string[]
}

// 播放器Hook(规划)
function useMusicPlayer() {
  return {
    play: (track: MusicTrack) => void,
    pause: () => void,
    next: () => void,
    previous: () => void,
    setVolume: (volume: number) => void,
    currentTrack: MusicTrack | null,
    isPlaying: boolean,
  }
}
\`\`\`

---

## 7. 环境适配与降级策略

### 7.1 环境检测

\`\`\`typescript
private isRestrictedEnvironment(): boolean {
  if (typeof window === "undefined") return true
  
  try {
    // iframe环境检测 (v0预览、嵌入页面等)
    return window.self !== window.top
  } catch {
    return true // 跨域iframe
  }
}
\`\`\`

### 7.2 降级策略

| 环境 | 语音识别 | 语音合成 | 音频分析 | 降级方案 |
|------|---------|---------|---------|---------|
| 标准浏览器 | 可用 | 可用 | 可用 | 完整功能 |
| iframe/v0预览 | 不可用 | 可用 | 不可用 | 文字输入+语音播报 |
| 无麦克风 | 不可用 | 可用 | 不可用 | 文字输入+语音播报 |
| 不支持Web Speech | 不可用 | 不可用 | 可能可用 | 纯文字交互 |

### 7.3 错误处理

\`\`\`typescript
// 统一错误处理

this.recognition.onerror = (event: any) => {
  switch(event.error) {
    case "network":
      // 网络错误 - 静默处理，提示使用文字
      console.log("[v0] 语音服务暂时不可用，请使用文字输入")
      break
    case "not-allowed":
      // 权限拒绝 - 引导用户授权
      console.log("[v0] 请允许麦克风权限以使用语音功能")
      break
    case "no-speech":
      // 无语音 - 静默忽略
      break
    default:
      console.error("[v0] 语音错误:", event.error)
  }
  
  this.isListening = false
}
\`\`\`

---

## 8. 性能优化

### 8.1 资源管理

\`\`\`typescript
// 音频分析器资源释放

releaseAudioAnalyser(): void {
  if (this.mediaStream) {
    this.mediaStream.getTracks().forEach((track) => track.stop())
    this.mediaStream = null
  }
  if (this.audioContext) {
    this.audioContext.close()
    this.audioContext = null
  }
  this.analyser = null
}
\`\`\`

### 8.2 单例模式

\`\`\`typescript
// 全局单例，避免重复实例化

let voiceSystemInstance: VoiceInteractionSystem | null = null

export function getVoiceSystem(): VoiceInteractionSystem {
  if (!voiceSystemInstance) {
    voiceSystemInstance = new VoiceInteractionSystem()
  }
  return voiceSystemInstance
}
\`\`\`

---

## 9. 项目文件清单

| 文件路径 | 功能描述 |
|---------|---------|
| `lib/voice/voice-system.ts` | 语音交互系统核心类 |
| `lib/speech.ts` | 语音服务工具类(简化版) |
| `lib/multimodal-fusion.ts` | 多模态情感融合算法 |
| `app/api/ai/emotion/route.ts` | 文本情感分析API |
| `hooks/useEmotionAnalysis.ts` | 情感分析React Hook |
| `components/ai-xiaoyu/VoiceInputButton.tsx` | 语音输入按钮组件 |
| `components/ai-xiaoyu/EmotionIndicator.tsx` | 情感指示器组件 |
| `components/growth/VoiceWaveAnimation.tsx` | 声波可视化动画 |

---

## 10. 未来演进方向

### 10.1 短期优化(1-2周)

- [ ] 集成Azure Speech Services提升识别准确率
- [ ] 添加离线语音模型支持
- [ ] 完善儿童语音特征优化
- [ ] 实现音乐播放器组件

### 10.2 中期规划(1个月)

- [ ] 接入流式语音合成(更低延迟)
- [ ] 实现声纹识别(多用户区分)
- [ ] 构建音乐推荐引擎
- [ ] 添加音乐可视化效果

### 10.3 长期愿景(3个月)

- [ ] AI音乐生成(基于情绪)
- [ ] 实时人声伴奏
- [ ] 多语言语音支持
- [ ] 语音故事自动生成

---

**文档版本**: v2.0  
**最后更新**: 2024年12月  
**维护团队**: YYC3 AI小语项目组
